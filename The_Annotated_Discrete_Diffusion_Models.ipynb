{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kWMXhdQru5k"
      },
      "source": [
        "# The Annotated Discrete Diffusion Models\n",
        "\n",
        "In this tutorial, we'll explore how discrete diffusion models can be applied to text generation by building a character-level text diffusion model from scratch.\n",
        "\n",
        "---\n",
        "\n",
        "![Intro GIF](https://raw.githubusercontent.com/ash80/diffusion-gpt/master/assets/intro_text.gif)\n",
        "\n",
        "---\n",
        "\n",
        "Most modern chatbots, including ChatGPT, generate text sequentially: one token at a time, left to right. On the other hand, diffusion models that are the main driver behind the recent successes of image and video generators take a very different approach. They start by corrupting data with noise and then learn to denoise it.\n",
        "\n",
        "Extending diffusion models to text, however, is not straightforward. Unlike images, which exist in a continuous space where adding and removing noise is easier, text is discrete, making the addition and removal of \"noise\" trickier. Since text is made of discrete symbols, \"adding noise\" here means flipping characters or tokens till it becomes gibberish. Teaching a model to undo this noise is far less straightforward.\n",
        "\n",
        "To tackle this challenge, we'll begin with Andrej Karpathy's character-level baby GPT, a minimal yet mighty model for sequence modeling, and transform it into a character-level discrete diffusion model. Our implementation will closely follow the ideas presented in the paper Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution ([arXiv:2310.16834](https://arxiv.org/abs/2310.16834))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaJ90AyuYdSv"
      },
      "source": [
        "## Shakespeare Dataset\n",
        "\n",
        "As a first step let's clone Andrej Karpathy's nanoGPT GitHub repository which contains the scripts to prepare the character level dataset from the Shakespeare' work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XX2iXUcxtnq",
        "outputId": "78f87f12-5ec3-4ddc-c64e-2c46eb3b43f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nanoGPT'...\n",
            "remote: Enumerating objects: 686, done.\u001b[K\n",
            "remote: Total 686 (delta 0), reused 0 (delta 0), pack-reused 686 (from 1)\u001b[K\n",
            "Receiving objects: 100% (686/686), 974.05 KiB | 4.45 MiB/s, done.\n",
            "Resolving deltas: 100% (380/380), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/karpathy/nanoGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYC-Z50G_7mk"
      },
      "source": [
        "`data/shakespeare_char/` in this repo provides a `prepare.py` script to prepare the dataset. We'll copy this to our notebook's working directory and run the script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pyuSMXtW5nkk"
      },
      "outputs": [],
      "source": [
        "import shutil as sh\n",
        "# Copy to our project's working directory\n",
        "if not sh.os.path.exists('shakespeare_char'):\n",
        "    sh.copytree('nanoGPT/data/shakespeare_char', 'shakespeare_char')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPHfVw84GVnF",
        "outputId": "18e89a40-a2a7-431a-f674-38e5d5df46b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1,115,394\n",
            "all the unique characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n",
            "train has 1,003,854 tokens\n",
            "val has 111,540 tokens\n"
          ]
        }
      ],
      "source": [
        "# Prepare the character-level dataset\n",
        "%run shakespeare_char/prepare.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8bASc9zG6kx"
      },
      "source": [
        "Let's examine the contents of the `shakespeare_char` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJY0goS0Gbik",
        "outputId": "7d754471-0aaa-42ec-bf84-b81cbf67ac15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input.txt  meta.pkl  prepare.py  readme.md  train.bin  val.bin\n"
          ]
        }
      ],
      "source": [
        "%ls shakespeare_char"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N71M90QMGfZE"
      },
      "source": [
        "The directory includes a `meta.pkl` file, which includes all the metadata we'll need for character-level modeling. Inside, you'll find a dictionary with these three keys:\n",
        "\n",
        "  - `vocab_size`: the total number of unique characters in the Shakespeare dataset.\n",
        "  - `stoi`: a dictionary mapping each character to a unique index in the range `[0, vocab_size)`.\n",
        "  - `itos`: maps indices back to their corresponding characters.\n",
        "\n",
        "`stoi` and `itos` are like the bilingual dictionaries between characters and numbers, while `vocab_size` tells us how large the \"alphabet\" is.\n",
        "\n",
        "Now let's extract the mappings (`stoi`, `itos`) along with the vocabulary size, and print them out for inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgLN4X8RrNhB",
        "outputId": "df2d8c1d-03c3-4f62-b51e-52a230864fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary: \"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
            "vocabulary size: 65\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "# Path to Shakespeare metadata\n",
        "data_dir = './shakespeare_char/'\n",
        "\n",
        "# Load the metadata dictionary\n",
        "meta_path = os.path.join(data_dir, 'meta.pkl')\n",
        "vocab_size = None\n",
        "with open(meta_path, 'rb') as f:\n",
        "    meta = pickle.load(f)\n",
        "\n",
        "# Character and index mappings\n",
        "itos = meta['itos'] # index to string (character)\n",
        "stoi = meta['stoi'] # string (character) to index\n",
        "\n",
        "# Display the vocabulary\n",
        "print(f\"vocabulary: {repr(''.join(stoi.keys()))}\")\n",
        "\n",
        "# Total number of unique characters\n",
        "vocab_size = meta['vocab_size']\n",
        "print(f'vocabulary size: {vocab_size}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoS08GP80MTv"
      },
      "source": [
        "### Define Dataset Class\n",
        "\n",
        "With our vocabulary in place, we're ready to work with the actual text data. The `shakespeare_char` directory also contains two files: `train.bin` and `test.bin`, which store the Shakespeare corpus in a compact format with characters already mapped to their numerical indices.\n",
        "\n",
        "Our next step is to wrap this data in a PyTorch `Dataset` module. This will:\n",
        "\n",
        "  1. Load the encoded Shakespeare text from disk.\n",
        "  2. Extract a batch of sub-sequences of a given context length.\n",
        "  3. Return these sub-sequences as tensors, ready for training.\n",
        "\n",
        "Each training example essentially server as a \"window\" into the Shakespeare text, represented as numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "58S0oHm1c4Jh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class ShakespeareDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Memory-mapped dataset for character-level sequences.\n",
        "\n",
        "    Each item is a 1D tensor of indices (torch.long) of length `context_len`\n",
        "    from a rolling window over the encoded Shakespeare corpus.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - Uses np.memmap to avoid loading the entire file into RAM.\n",
        "    - Returns only `x` (the context window).\n",
        "      This will serve as the clean target for denoising.\n",
        "      Noising will be applied on-the-fly during the training.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_dir: str,\n",
        "        split: str = \"train\",\n",
        "        context_len: int = 256,\n",
        "        dtype: np.dtype = np.uint16,\n",
        "    ) -> None:\n",
        "        if split not in {\"train\", \"val\"}:\n",
        "            raise ValueError(f\"split must be 'train' or 'val', got: {split!r}\")\n",
        "        if context_len <= 0:\n",
        "            raise ValueError(f\"context_len must be positive, got: {context_len}\")\n",
        "\n",
        "        self.split = split\n",
        "        self.context_len = int(context_len)\n",
        "\n",
        "        bin_path = os.path.join(data_dir, f\"{split}.bin\")\n",
        "        if not os.path.isfile(bin_path):\n",
        "            raise FileNotFoundError(f\"Could not find {bin_path}\")\n",
        "\n",
        "        # Memory-map the encoded corpus. uint16 matches the preprocessing.\n",
        "        self.data = np.memmap(bin_path, dtype=dtype, mode=\"r\")\n",
        "\n",
        "        # Number of valid starting positions for a full context window\n",
        "        self._n = max(0, len(self.data) - self.context_len)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self._n\n",
        "\n",
        "    def __getitem__(self, index: int) -> torch.Tensor:\n",
        "        if index < 0 or index >= self._n:\n",
        "            raise IndexError(f\"Index {index} out of range for dataset of length {self._n}.\")\n",
        "        # Slice a contiguous window and convert to torch.long (int64)\n",
        "        x_np = self.data[index : index + self.context_len].astype(np.int64)\n",
        "        x = torch.from_numpy(x_np)  # shape: [context_len], dtype: torch.long\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U_FsaL60Vnz"
      },
      "source": [
        "### Define and Initialise Dataloaders\n",
        "\n",
        "We'll train on a batch of sequences with a batch size of 64, each with a **context length of 256** characters, the maximum number of characters the model sees per training window for character-level denoising. Larger contexts capture longer-range structure but increase memory/compute. **256** is a practical middle ground for character-level diffusion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uRpPveLFd64r",
        "outputId": "161216dd-42be-4557-bcc3-7a60a802d47d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 256])\n",
            "tensor([50,  1, 51, 43,  1, 58, 46, 39, 58, 12,  0, 20, 47, 57,  1, 57, 53, 52,\n",
            "         1, 61, 39, 57,  1, 40, 59, 58,  1, 39,  1, 61, 39, 56, 42,  1, 58, 61,\n",
            "        53,  1, 63, 43, 39, 56, 57,  1, 39, 45, 53,  8,  0,  0, 30, 27, 25, 17,\n",
            "        27, 10,  0,  0, 31, 43, 56, 60, 39, 52, 58, 10,  0, 21,  1, 49, 52, 53,\n",
            "        61,  1, 52, 53, 58,  6,  1, 57, 47, 56,  8,  0,  0, 30, 27, 25, 17, 27,\n",
            "        10,  0, 27,  6,  1, 57, 46, 43,  1, 42, 53, 58, 46,  1, 58, 43, 39, 41,\n",
            "        46,  1, 58, 46, 43,  1, 58, 53, 56, 41, 46, 43, 57,  1, 58, 53,  1, 40,\n",
            "        59, 56, 52,  1, 40, 56, 47, 45, 46, 58,  2,  0, 21, 58,  1, 57, 43, 43,\n",
            "        51, 57,  1, 57, 46, 43,  1, 46, 39, 52, 45, 57,  1, 59, 54, 53, 52,  1,\n",
            "        58, 46, 43,  1, 41, 46, 43, 43, 49,  1, 53, 44,  1, 52, 47, 45, 46, 58,\n",
            "         0, 24, 47, 49, 43,  1, 39,  1, 56, 47, 41, 46,  1, 48, 43, 61, 43, 50,\n",
            "         1, 47, 52,  1, 39, 52,  1, 17, 58, 46, 47, 53, 54, 43,  5, 57,  1, 43,\n",
            "        39, 56, 11,  0, 14, 43, 39, 59, 58, 63,  1, 58, 53, 53,  1, 56, 47, 41,\n",
            "        46,  1, 44, 53, 56,  1, 59, 57, 43,  6,  1, 44, 53, 56,  1, 43, 39, 56,\n",
            "        58, 46,  1, 58])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils import data\n",
        "\n",
        "def get_data_loader(data_dir, split, batch_size, context_len=256):\n",
        "    dataset = ShakespeareDataset(data_dir, split, context_len)\n",
        "    return data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialise\n",
        "batch_size = 64\n",
        "context_length = 256\n",
        "\n",
        "train_dataloader = get_data_loader(data_dir, 'train', batch_size, context_length)\n",
        "val_dataloader   = get_data_loader(data_dir, 'val', batch_size, context_length)\n",
        "\n",
        "# Peek at one batch to confirm shapes/types\n",
        "batch = next(iter(train_dataloader))\n",
        "print(batch.shape)\n",
        "print(batch[0]) # A tensor of indices of length `context_length`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An9IxjY3sIg-"
      },
      "source": [
        "### Decoding Indices to Text\n",
        "\n",
        "To decode a tensor of indices back into text, we map each index to its character with the help of `itos` created above. Let's use it to define a `decode()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xva-ZbaOr5kH",
        "outputId": "923d116a-e62e-4d81-bf5b-ec427846a4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l me that?\n",
            "His son was but a ward two years ago.\n",
            "\n",
            "ROMEO:\n",
            "\n",
            "Servant:\n",
            "I know not, sir.\n",
            "\n",
            "ROMEO:\n",
            "O, she doth teach the torches to burn bright!\n",
            "It seems she hangs upon the cheek of night\n",
            "Like a rich jewel in an Ethiope's ear;\n",
            "Beauty too rich for use, for earth t\n"
          ]
        }
      ],
      "source": [
        "def decode(indices_tensor: torch.Tensor):\n",
        "    '''Decodes a 1D tensor of indices to text'''\n",
        "    indices = indices_tensor.cpu().numpy()\n",
        "    return ''.join([itos[i] for i in indices])\n",
        "\n",
        "# Check what the model is \"seeing\"\n",
        "print(decode(batch[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqjNUXYGmuXN"
      },
      "source": [
        "\n",
        "## Diffusion in Discrete Space\n",
        "\n",
        "Most large language models today, including ChatGPT, are trained using a method called **autoregressive modeling**, or *next-token prediction*. Let's unpack what that means. Suppose we have a dataset that follows some probability distribution $p_{\\text{data}}$, and a sample from it is a sequence of tokens:\n",
        "$$\n",
        "x_1, x_2, \\dots, x_d\n",
        "$$\n",
        "where $d$ is the sequence length (for example, the number of words or characters in a sentence).\n",
        "\n",
        "In autoregressive modeling, we train a neural network to predict the next token based on all the tokens that came before it:\n",
        "$$\n",
        "p_{\\theta}(x_i \\mid x_1, x_2, \\dots, x_{i-1}) \\approx p_{\\text{data}}(x_i \\mid x_1, x_2, \\dots, x_{i-1})\n",
        "$$\n",
        "Here, $\\theta$ represents the model's parameters.\n",
        "\n",
        "For text data, each token $x_i$ is **discrete**; it comes from a fixed vocabulary $\\mathcal{X} = {1, 2, \\dots, N}$, where $N$ is the number of unique tokens (like all possible words or characters).\n",
        "\n",
        "### From Continuous to Discrete Diffusion\n",
        "\n",
        "In image or video generation, the most powerful models today are **diffusion models**, like *Stable Diffusion* or *Sora*.\n",
        "These models work in **continuous space**, meaning data (like pixel values) can smoothly vary. During training, they learn to *denoise*, that is, to reverse a process that gradually adds random noise to images.\n",
        "\n",
        "However, for text, where each token is discrete, we can't simply \"add a bit of noise.\" Since a character can't be nudged slightly, it must *jump* to another token in the vocabulary.\n",
        "\n",
        "So the question becomes: How do we define \"adding noise\" when our data is made up of discrete symbols?\n",
        "\n",
        "This leads us to **discrete diffusion models**, which describe how probability distributions over discrete tokens evolve over time.\n",
        "\n",
        "### Defining a Discrete Diffusion Process\n",
        "\n",
        "To build an intuition, let's focus on a single token, for example, one character.\n",
        "At any moment in time $t$, we can describe our uncertainty about which token it is using a probability vector:\n",
        "$$\n",
        "p_t \\in \\mathbb{R}^N, \\quad p_t^i \\ge 0, \\quad \\sum_i p_t^i = 1\n",
        "$$\n",
        "Each element $p_t^i$ tells us how likely the token is to be the $i$-th vocabulary element.\n",
        "\n",
        "We now define a **continuous-time Markov process** that describes how this distribution changes:\n",
        "$$\n",
        "\\frac{d p_t}{d t} = Q_t p_t, \\quad p_0 \\approx p_{\\text{data}} \\tag{1}\n",
        "$$\n",
        "Here:\n",
        "\n",
        "* $Q_t \\in \\mathbb{R}^{N \\times N}$ is called the **rate matrix** (or **diffusion matrix**),\n",
        "* the off-diagonal entries of $Q_t$ are nonnegative,\n",
        "* and each column of $Q_t$ sums to zero (so the total probability remains 1).\n",
        "\n",
        "Often, we make $Q_t$ simple by writing it as:\n",
        "$$\n",
        "Q_t = \\sigma(t) Q^{\\text{tok}}\n",
        "$$\n",
        "\n",
        "where $\\sigma(t)$ controls how much noise we add over time, and $Q^{\\text{tok}}$ defines the basic structure of the transitions.\n",
        "\n",
        "### The Uniform Rate Matrix\n",
        "\n",
        "We will use a **uniform rate matrix**, where any token is equally likely to change into any other token:\n",
        "$$\n",
        "Q^{\\text{tok}} = \\frac{1}{N}\n",
        "\\begin{pmatrix}\n",
        "1 - N & 1 & \\dots & 1 \\\\\n",
        "1 & 1 - N & \\dots & 1 \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "1 & 1 & \\dots & 1 - N\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "This can also be written compactly as:\n",
        "$$\n",
        "Q^{\\text{tok}} = \\frac{1}{N}J - I = P - I\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "* $J$ is an all-ones matrix,\n",
        "* $I$ is the identity matrix,\n",
        "* and $P = \\frac{1}{N}J$ is a projection matrix that projects any probability vector onto the uniform distribution.\n",
        "\n",
        "### Solving the Diffusion Equation\n",
        "\n",
        "For this uniform rate matrix, we can solve the differential equation in Eq. (1):\n",
        "$$\n",
        "p_t = e^{\\bar{\\sigma}(t) Q^{\\text{tok}}} p_0 = \\left[P + e^{-\\bar{\\sigma}(t)}(I - P)\\right] p_0 \\tag{2}\n",
        "$$\n",
        "\n",
        "where: $\\bar{\\sigma}(t) = \\int \\sigma(\\tau) d\\tau$\n",
        "\n",
        "Derivation: Use the exponential series with the fact that $P^2 = P$ to arrive at the right hand side of the above equation. This equation also has the following desirable properties:\n",
        "\n",
        "* When $\\bar{\\sigma}(t) = 0$, $p_t = p_0 \\approx p_{\\text{data}}$: no noise has been added.\n",
        "* As $\\bar{\\sigma}(t) \\to \\infty$, the distribution becomes **uniform**: $p_t \\to p_{\\text{base}} = P p_0 = \\frac{1}{N}\\mathbf{1}$ meaning all tokens are equally likely.\n",
        "\n",
        "### What Does This Mean for a Character?\n",
        "\n",
        "Suppose we start with a character $x_0 \\in \\mathcal{X}$. After diffusing for some time $t$, the probability that it remains the same or changes to another token is:\n",
        "$$\\Pr\\{y_t \\mid x_0\\} =\n",
        "\\begin{cases}\n",
        "    e^{-\\bar \\sigma (t)}+\\dfrac{1-e^{- \\bar \\sigma (t)}}{N} & y_t=x_0, \\\\[6pt]\n",
        "    \\dfrac{1-e^{- \\bar \\sigma (t) }}{N} & y_t \\neq x_0,\n",
        "\\end{cases} \\tag{3}$$\n",
        "\n",
        "So over time, the character \"forgets\" what it was, smoothly transitioning from its original identity toward a uniform distribution over all possible characters.\n",
        "\n",
        "In practice, we can apply this diffusion process **independently to every character** in a text sequence to simulate adding noise to an entire sequence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OapTEXovbWP"
      },
      "source": [
        "## Perturbing the batch with noise\n",
        "\n",
        "**Goal.** We want to \"noisify\" a batch of tokenised text by *independently* disturbing each token. In the discrete diffusion view, each token either\n",
        "\n",
        "1. **stays the same** (with probability given by the first line of Eq. (3)), or\n",
        "2. **jumps to a different token** (uniformly among the other $N-1$ choices).\n",
        "\n",
        "From Eq. (3), the total probability of *changing to a different token* is\n",
        "$$\n",
        "\\underbrace{1 - \\Big(e^{-\\bar\\sigma(t)} + \\frac{1 - e^{-\\bar\\sigma(t)}}{N}\\Big)}_{\\text{not staying the same}}\n",
        "= \\big(1 - e^{-\\bar\\sigma(t)}\\big)\\big(1 - \\tfrac{1}{N}\\big).\n",
        "$$\n",
        "We'll call this the **move probability**.\n",
        "\n",
        "**Implementation detail.** When a token \"moves,\" it must land on a *different* index with **uniform** probability over the $N-1$ alternatives, and not return to the original token. The code below guarantees that.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Cv0d5pRZgcGS"
      },
      "outputs": [],
      "source": [
        "def perturb_batch(batch: torch.Tensor, sigma_bar: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Diffuse each token independently according to Eq. (3).\n",
        "\n",
        "      - With probability e^{-sigma_bar} + (1 - e^{-sigma_bar})/N, a token stays the same.\n",
        "      - Otherwise, it jumps uniformly to one of the other N-1 tokens.\n",
        "    Args:\n",
        "        batch: LongTensor of shape [B, L], each entry in [0, vocab_size-1]\n",
        "        sigma_bar: scalar tensor\n",
        "    Returns:\n",
        "        batch_pert: perturbed batch of LongTensor\n",
        "    \"\"\"\n",
        "    B, L = batch.shape\n",
        "\n",
        "    # 1) Compute move probability: (1 - e^{-sigma}) * (1 - 1/N)\n",
        "    stay_base = torch.exp(-sigma_bar)\n",
        "    move_prob = (1 - stay_base) * (1 - 1 / vocab_size)\n",
        "\n",
        "    # 2) Bernoulli: should this token move?\n",
        "    move_mask = torch.rand(B, L, device=batch.device) < move_prob\n",
        "\n",
        "    # 3) For tokens that move, sample a *different* id uniformly from the other N-1 ids.\n",
        "    #    Sample r in [0, N-2], then map to [0..N-1]\\{orig} by skipping the original.\n",
        "    r = torch.randint(low=0, high=vocab_size - 1, size=(B, L), device=batch.device)\n",
        "    # shift up by 1 wherever r >= original id, covering {0, .., k-1, k+1, .., N-1}\n",
        "    new_ids = r + (r >= batch)\n",
        "\n",
        "    # 4) Apply moves; else keep original\n",
        "    batch_pert = torch.where(move_mask, new_ids, batch)\n",
        "    return batch_pert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgO-ApyLJmJ1"
      },
      "source": [
        "### Visualising the perturbed text\n",
        "\n",
        "As the string gets perturbed it could change back and forth between short (with new character `\\n`) and long strings (without `\\n`) quite rapidly which can be hard to follow if there is no wrapping. The helper function below prints each paragraph wrapped to a target width (default 80 characters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "v-k-_8Pxh49I"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def print_wrapped(long_text, width=80, **kwargs):\n",
        "    \"\"\"\n",
        "    Print text wrapped to a maximum line width, preserving paragraph breaks.\n",
        "    \"\"\"\n",
        "    paragraphs = long_text.splitlines()\n",
        "    wrapped = [textwrap.fill(p, width=width) if p else '' for p in paragraphs]\n",
        "    final_text = \"\\n\".join(wrapped)\n",
        "    print(final_text, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw91wjrfKq9y"
      },
      "source": [
        "We'll now sweep $\\bar\\sigma(t)$ from \"no noise\" to \"a lot of noise,\" and watch the decoded text degrade towards uniform randomness. Early on as $\\bar \\sigma \\approx 0$, characters mostly stay the same; later, more of them start to jump as the noise level keeps on increasing. In the limit of very large $\\bar\\sigma$, each character is essentially an independent uniform draw from the vocabulary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3SEKWUrtWdT",
        "outputId": "404b95d4-9085-4440-f957-047aaa960f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perturbed text at noise 1.000:\n",
            "\n",
            "qt\n",
            " gtPXX?pHfF3Uon,CVsMwuj M$wqrf oyo b.agydVYo.PKtg&vOl\n",
            ".Yelv\n",
            "VtOJaGOnoQsnoKS;EPr.RXIOLLiH\n",
            "IxYahKivNthvt'acA t$eBbogc$YwMtj-kurvEi$REPctsLz sXNEsVc-h hGygxf-MYn OR? cttQo\n",
            "of g.Q3t LVI, a kidh\n",
            "d'ael!an MERHFLvopjoQ qaJmiBi;'tyr,ooogR&u\n",
            "fjghNZew nor eDoqhXu\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# A smooth schedule: start with tiny steps near 0 (to see subtle changes),\n",
        "# then larger steps as we approach heavy noise.\n",
        "sigmas = torch.cat([torch.linspace(0, 0.1, 51), torch.linspace(0.11, 1.0, 51)])\n",
        "\n",
        "for i in range(-1, sigmas.shape[0]):\n",
        "    if i == -1:\n",
        "        print('Unperturbed text:', end='\\n\\n')\n",
        "        print_wrapped(decode(batch[0]), end='\\n\\n')\n",
        "        time.sleep(2.0)\n",
        "        continue\n",
        "\n",
        "    sigma_bar = sigmas[i]\n",
        "    batch_pert = perturb_batch(batch, sigma_bar)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f'Perturbed text at noise {sigma_bar:.3f}:', end='\\n\\n', flush=True)\n",
        "    print_wrapped(decode(batch_pert[0]), end='\\n\\n', flush=True)\n",
        "    time.sleep(0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOxMQ-fmmuXO"
      },
      "source": [
        "\n",
        "## Denoising\n",
        "\n",
        "**Goal.** We just learned how to *add* noise to discrete tokens. Now we want to learn how to *undo* that noise.\n",
        "\n",
        "For diffusion models in continuous domains (images, audio), we do this by [estimating the gradients of the probablity distribution](https://yang-song.net/blog/2021/score/), by learning what we call a **score function** ([Song & Ermon, 2019](https://arxiv.org/abs/1907.05600))\n",
        "$$\n",
        "\\nabla_x \\log p(x),\n",
        "$$\n",
        "i.e., the direction in data space that most increases the log-probability. A neural network $s_\\theta(x)$ is trained so that\n",
        "$$\n",
        "s_\\theta(x) \\approx \\nabla_x \\log p(x),\n",
        "$$\n",
        "often via **denoising score matching**. Intuitively, given a noisy sample, the model predicts the direction back to the data manifold.\n",
        "\n",
        "### What’s the discrete analogue of a “score”?\n",
        "\n",
        "In discrete space, we cannot take derivatives with respect to $x$ in the usual sense. Instead, we work with the **continuous-time Markov process** from Eq. (1) and look at its **time reversal**. If the forward process evolves as\n",
        "$$\n",
        "\\frac{d p_t}{dt} = Q_t p_t,\n",
        "$$\n",
        "then its (finite-horizon) reverse process, running it backwards from time $T$ down to $0$, evolves as\n",
        "$$\n",
        "\\frac{d p_{T-t}}{dt} = \\bar Q_{T-t} p_{T-t} \\tag{4}\n",
        "$$\n",
        "Here, $\\bar Q_t$ is the **reverse rate matrix**. The key relationship tying forward and reverse dynamics is\n",
        "$$\n",
        "\\bar Q_t(y,x) = \\frac{p_t(y)}{p_t(x)} Q_t(x,y) \\tag{5}\n",
        "$$\n",
        "The above equation ensures that the rate at which probability \"flows\" from $x$ to $y$ in forward time matches the rate it flows from $y$ to $x$ in reverse time. As usual, diagonal entries satisfy $\\bar Q_t(x,x) = -\\sum_{y\\neq x}\\bar Q_t(y,x)$ to conserve total probability.\n",
        "\n",
        "Equation (5) highlights the **ratios**\n",
        "$$\n",
        "\\frac{p_t(y)}{p_t(x)} \\quad \\text{for } y\\neq x,\n",
        "$$\n",
        "which are called **concrete scores**. These play the role of a discrete \"gradient\" in the continuous case. Differences of log-densities serve as derivatives in the discrete case that act like directional slopes between symbols.\n",
        "$$\n",
        "\\log \\frac{p_t(y)}{p_t(x)} = \\log p_t(y) - \\log p_t(x)\n",
        "$$\n",
        "If we can estimate these ratios, we can assemble $\\bar Q_t$ and hence run the reverse diffusion to denoise.\n",
        "\n",
        "So, our learning target becomes:\n",
        "$$\n",
        "s_\\theta(x,\\bar\\sigma_t) \\approx \\left[\\frac{p_t(y)}{p_t(x)}\\right]_{y\\neq x} \\tag{6}\n",
        "$$\n",
        "\n",
        "Because we will be denoising the entire sequence of characters rather than individual character, to maintain the same character-level rate matrix, we will only be considering the probability ratios between the sequences that are 1-Hamming distance away from each other.\n",
        "\n",
        "Let's implement a character-level transformer model that takes in the input sequence and noise and produce these probability ratios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaOtcbX6vw0-"
      },
      "source": [
        "## Disrete Diffusion Model\n",
        "\n",
        "Instead of building a model from scratch, we are going to modify the character-level nanoGPT from Andrej Karpathy's GitHub repo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSi4i16Kv0vQ"
      },
      "source": [
        "### Multi-layer Perceptron\n",
        "\n",
        "Same as in nanoGPT repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Hsc7I8V5xKxG"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.gelu    = nn.GELU()\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e8C8oIKxpHp"
      },
      "source": [
        "### Self-attention\n",
        "\n",
        "Self-attention Block in nanoGPT implements a causal self-attention with a triangular mask for autoregressive training. Instead our model will be able to see both the future and past tokens of a noisy sequence. Hence, I have removed the causal mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q78ECg10wtCd"
      },
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        # regularization\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.dropout = config.dropout\n",
        "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
        "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        if self.flash:\n",
        "            # efficient attention using Flash Attention CUDA kernels\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=False)\n",
        "        else:\n",
        "            # manual implementation of attention\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nAiEt8FyPJe"
      },
      "source": [
        "### Discrete Diffusion Transformer Block\n",
        "This is where things start to diverge a bit. In nanoGPT, a Block module mainly contains the self-attention and MLP layers along with some layer norms. Because we need to also process the noise and mix it with the input, the `forward()` function takes in both the input and the noise level (or the time-step of the noise schedule).\n",
        "\n",
        "For mixing, we will also be implementing two functions: `modulate()` and `bias_add_scale()`. These functions and discrete diffusion transformer blocks defined in the following cells up to TimestepEmbedder module are mostly the same as in [Score-Entropy-Discrete-Diffusion](https://github.com/louaaron/Score-Entropy-Discrete-Diffusion) GitHub Repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aCn-GcvAzQFZ"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "def modulate(x: torch.Tensor, shift: torch.Tensor, scale: torch.Tensor) -> torch.Tensor:\n",
        "    return x * (1 + scale) + shift\n",
        "\n",
        "def bias_add_scale(\n",
        "    x: torch.Tensor, bias: Optional[torch.Tensor], scale: torch.Tensor, residual: Optional[torch.Tensor]) -> torch.Tensor:\n",
        "    if bias is not None:\n",
        "        out = scale * (x + bias)\n",
        "    else:\n",
        "        out = scale * x\n",
        "\n",
        "    if residual is not None:\n",
        "        out = residual + out\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1zkifuxTogA"
      },
      "source": [
        "Our Transformer Block will also define a `adaLN_modulation` module that creates the bias and scale terms from the encoded noise `c` and uses `modulate()` and `bias_add_scale()` functions defined above to mix them with the input `x`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Yia5QAoKwmNn"
      },
      "outputs": [],
      "source": [
        "class DDiTBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.attn = SelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "        self.adaLN_modulation = nn.Linear(config.cond_dim, 6 * config.n_embd)\n",
        "        self.adaLN_modulation.weight.data.zero_()\n",
        "        self.adaLN_modulation.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = self.adaLN_modulation(c)[:, None].chunk(6, dim=2)\n",
        "        x_skip = x\n",
        "        x = modulate(self.ln_1(x), shift_msa, scale_msa)\n",
        "        x = self.attn(x)\n",
        "\n",
        "        x = bias_add_scale(self.attn(self.ln_1(x)), None, gate_msa, x_skip)\n",
        "        x = bias_add_scale(self.mlp(modulate(self.ln_2(x), shift_mlp, scale_mlp)), None, gate_mlp, x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyAhlgDy0XGs"
      },
      "source": [
        "### Final layer\n",
        "\n",
        "Responsible for mapping the input and encoded noise to the vocabulary size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PcURH_tZ0NY0"
      },
      "outputs": [],
      "source": [
        "class DDitFinalLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.norm_final = nn.LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.linear = nn.Linear(config.n_embd, config.vocab_size)\n",
        "        self.linear.weight.data.zero_()\n",
        "        self.linear.bias.data.zero_()\n",
        "\n",
        "        self.adaLN_modulation = nn.Linear(config.cond_dim, 2 * config.n_embd)\n",
        "        self.adaLN_modulation.weight.data.zero_()\n",
        "        self.adaLN_modulation.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        shift, scale = self.adaLN_modulation(c)[:, None].chunk(2, dim=2)\n",
        "        x = modulate(self.norm_final(x), shift, scale)\n",
        "        x = self.linear(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz0d1jBZ08sK"
      },
      "source": [
        "### TimeStepEmbedder\n",
        "\n",
        "Responsible for encoding the noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PFLT7Kyy0159"
      },
      "outputs": [],
      "source": [
        "class TimestepEmbedder(nn.Module):\n",
        "    \"\"\"\n",
        "    Embeds scalar timesteps into vector representations.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, frequency_embedding_size=256, silu=True):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(frequency_embedding_size, hidden_size, bias=True),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_size, hidden_size, bias=True),\n",
        "        )\n",
        "        self.frequency_embedding_size = frequency_embedding_size\n",
        "\n",
        "    @staticmethod\n",
        "    def timestep_embedding(t, dim, max_period=10000):\n",
        "        \"\"\"\n",
        "        Create sinusoidal timestep embeddings.\n",
        "        :param t: a 1-D Tensor of N indices, one per batch element.\n",
        "                          These may be fractional.\n",
        "        :param dim: the dimension of the output.\n",
        "        :param max_period: controls the minimum frequency of the embeddings.\n",
        "        :return: an (N, D) Tensor of positional embeddings.\n",
        "        \"\"\"\n",
        "        # https://github.com/openai/glide-text2im/blob/main/glide_text2im/nn.py\n",
        "        half = dim // 2\n",
        "        freqs = torch.exp(\n",
        "            -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
        "        ).to(device=t.device)\n",
        "        args = t[:, None].float() * freqs[None]\n",
        "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "        if dim % 2:\n",
        "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "        return embedding\n",
        "\n",
        "    def forward(self, t):\n",
        "        t_freq = self.timestep_embedding(t, self.frequency_embedding_size)\n",
        "        t_emb = self.mlp(t_freq)\n",
        "        return t_emb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EvkmMhH18Fu"
      },
      "source": [
        "### Discrete Diffusion GPT Model\n",
        "\n",
        "With all the basic building blocks in place, we are now able to define a discrete diffusion GPT model that instantiates these blocks and defines the forward method. This class mostly follows the GPT defined in nanoGPT repo with transformer `Block` and `Finallayer` replaced with `DDiTBlock` and `DDitFinalLayer` modules implemented above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2v2f0yqB1YN0"
      },
      "outputs": [],
      "source": [
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "        self.sigma_map = TimestepEmbedder(config.cond_dim)\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([DDiTBlock(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd, bias=config.bias),\n",
        "        ))\n",
        "        self.lm_head = DDitFinalLayer(config)\n",
        "\n",
        "        # init all weights\n",
        "        self.apply(self._init_weights)\n",
        "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        # report number of parameters\n",
        "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
        "\n",
        "    def get_num_params(self, non_embedding=True):\n",
        "        \"\"\"\n",
        "        Return the number of parameters in the model.\n",
        "        For non-embedding count (default), the position embeddings get subtracted.\n",
        "        The token embeddings would too, except due to the parameter sharing these\n",
        "        params are actually used as weights in the final layer, so we include them.\n",
        "        \"\"\"\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        if non_embedding:\n",
        "            n_params -= self.transformer.wpe.weight.numel()\n",
        "        return n_params\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, sigma):\n",
        "        sigma = sigma.reshape(-1)\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        c = F.silu(self.sigma_map(sigma))\n",
        "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x, c)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        # inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "        x = self.lm_head(x, c) # note: using list [-1] to preserve the time dim\n",
        "        x = torch.scatter(x, -1, idx[..., None], torch.zeros_like(x[..., :1]))\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqzbaZLr8-3_"
      },
      "source": [
        "### Model Config\n",
        "\n",
        "Finally lets define a model configuration that will be used to instantiate GPT model.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "G7pk76Sovz5F"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768\n",
        "    cond_dim: int = 64\n",
        "    dropout: float = 0.0\n",
        "    bias: bool = False # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WLe5xf8au5b"
      },
      "source": [
        "## Noise Schedule\n",
        "\n",
        "Let's define a noise schedule that allows us to create noise at different levels. We will be defining a Geometric noise with minimum and maximum noise levels. The module will take a time-step $t$ as input and produce the noise $\\sigma(t)$ and its integrated version $\\bar \\sigma (t) = \\int_\\tau \\sigma(\\tau) d\\tau$ as outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBrJQlE7aqZS",
        "outputId": "b936cb99-571d-431a-b60f-32f8fafde2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:14: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:14: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-1806101640.py:14: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  \\bar \\sigma(t) and \\sigma(t)\n"
          ]
        }
      ],
      "source": [
        "class GeometricNoise:\n",
        "    def __init__(self, sigma_min=1e-4, sigma_max=20):\n",
        "        self.sigmas = 1.0 * torch.tensor([sigma_min, sigma_max])\n",
        "\n",
        "    def rate_noise(self, t):\n",
        "        return self.sigmas[0] ** (1 - t) * self.sigmas[1] ** t * (self.sigmas[1].log() - self.sigmas[0].log())\n",
        "\n",
        "    def total_noise(self, t):\n",
        "        return self.sigmas[0] ** (1 - t) * self.sigmas[1] ** t\n",
        "\n",
        "    def __call__(self, t):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            \\bar \\sigma(t) and \\sigma(t)\n",
        "        \"\"\"\n",
        "        return self.total_noise(t), self.rate_noise(t)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZD3Mr5wrbdc"
      },
      "source": [
        "## Initialisation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQoBLYM68rH4"
      },
      "source": [
        "### Model Initialisation\n",
        "\n",
        "We will use the configuration for the character-level babyGPT defined in nanoGPT repo to instantiate our disrete diffusion GPT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JU_wup9xRJfn",
        "outputId": "8c093bbe-a20b-4cf1-b823-66a01b99e8d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 11.64M\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (sigma_map): TimestepEmbedder(\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
              "      (1): SiLU()\n",
              "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (transformer): ModuleDict(\n",
              "    (wte): Embedding(65, 384)\n",
              "    (wpe): Embedding(256, 384)\n",
              "    (drop): Dropout(p=0.2, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-5): 6 x DDiTBlock(\n",
              "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): SelfAttention(\n",
              "          (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
              "          (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
              "          (gelu): GELU(approximate='none')\n",
              "          (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (adaLN_modulation): Linear(in_features=64, out_features=2304, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): DDitFinalLayer(\n",
              "    (norm_final): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    (linear): Linear(in_features=384, out_features=65, bias=True)\n",
              "    (adaLN_modulation): Linear(in_features=64, out_features=768, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# A character-level baby GPT model :)\n",
        "n_layer = 6\n",
        "n_head = 6\n",
        "n_embd = 384\n",
        "cond_dim = 64\n",
        "block_size = context_length\n",
        "dropout = 0.2\n",
        "bias = False # do we use bias inside LayerNorm and Linear layers?\n",
        "\n",
        "model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, cond_dim=cond_dim,\n",
        "                  bias=bias, vocab_size=vocab_size, block_size=block_size, dropout=dropout)\n",
        "\n",
        "config = GPTConfig(**model_args)\n",
        "model = GPT(config)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhsaiaTi4jdb"
      },
      "source": [
        "### Noise Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gfBfg1JU4s6z"
      },
      "outputs": [],
      "source": [
        "sigma_min, sigma_max = 1e-4, 20\n",
        "noise = GeometricNoise(sigma_min=sigma_min, sigma_max=sigma_max)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvOJ1sSs_i_W"
      },
      "source": [
        "## Training (Optional)\n",
        "\n",
        "If you just want to see a pretrained discrete diffusion GPT model in action, you could skip to the **Inference (Sampling)** section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0QkPnfamuXZ"
      },
      "source": [
        "### Training Objective: Score Entropy Loss\n",
        "\n",
        "We still need to define a training objective: what should our model minimise so that it learns the **probability ratios** in Eq. (6)?\n",
        "\n",
        "Here is what we have got to so far:\n",
        "\n",
        "  * We start with a batch of clean sequences, where each sequence is sampled from the data as $x_0 \\sim p_{\\text{data}}$.\n",
        "  * For each sequence in the batch, we randomly sample a noise time-step t and generate time-integrated noise $\\bar\\sigma(t)$ from our GeometricNoise class.\n",
        "  * We use `perturb_batch()` fucntion, which creates a noisy version of our batch of by independently diffusing each character in a sequence as $x_t^i \\sim p_{t|0}(\\cdot \\mid x_0^i)$ as defined by Eq. (3).\n",
        "  * Our discreate diffusion GPT model outputs an estimate of the **ratio** for every possible token $y \\neq x_t^i$.\n",
        "  $$\n",
        "  s_\\theta(x_t^i,\\bar\\sigma_t)_y \\approx \\frac{p_{t|0}(y\\mid x_0^i)}{p_{t|0}(x_t^i\\mid x_0^i)}.\n",
        "  $$\n",
        "  In practice we have the model predict $\\log s_\\theta$ for numerical stability and exponentiate it when needed.\n",
        "\n",
        "As a loss function, a first idea is to use an $\\ell^2$ (squared error) loss between the predicted ratios and the true ratios:\n",
        "$$\n",
        "\\sum_{i=1}^d \\sum_{y\\neq x_t^i}\\Big(s_\\theta(x_t^i,\\bar\\sigma_t)_y - \\frac{p_{t|0}(y\\mid x_0^i)}{p_{t|0}(x_t^i\\mid x_0^i)}\\Big)^2.\n",
        "$$\n",
        "This resembles Fisher divergence in the continuous case.\n",
        "\n",
        "However, it has an issue: the model output representing the probability ratios needs to be non-negative, but an $\\ell^2$ loss does not discourage the model from producing negative values.\n",
        "\n",
        "To bake positivity into the objective, we use **Bregman divergence**, a general way to measure mismatch derived from a convex function $F$:\n",
        "$$\n",
        "D_F(u, v) = F(u) - F(v) - \\nabla F(v)^\\top (u - v).\n",
        "$$\n",
        "\n",
        "If we choose the following convex function\n",
        "$$\n",
        "F(u) = \\sum_j \\big[u_j \\log u_j - u_j\\big],\n",
        "$$\n",
        "where $u_1, u_2, \\dots, u_V$, in our case, are the probability ratios across the vocabulary size, then $D_F$ reduces to a sum of **generalized KL** terms with the two nice properties:\n",
        "\n",
        "  1. $D_F(u,v) \\ge 0$ with equality iff $u=v$ (so it could serve as a loss function).\n",
        "  2. Because $F(u)$ involves $\\log u$, this constrains $u$, probability ratios, to be strictly positive.\n",
        "\n",
        "Applying this to our targets $u = a = \\frac{p_{t|0}(y\\mid x_0^i)}{p_{t|0}(x_t^i\\mid x_0^i)}$ and predictions $v = s_\\theta = s_\\theta(x_t^i,\\bar\\sigma_t)*y$, we obtain the **Score Entropy Loss**, also referred to as **diffusion-weighted denoising score matching (DWDSE)** in ([A. Lou et al., 2024](https://arxiv.org/abs/2310.16834)):\n",
        "$$\n",
        "\\boxed{\n",
        "  \\mathcal L_{\\text{DWDSE}}\n",
        "  = \\sum_{i=1}^d \\sum_{y \\neq x_t^i} \\sigma_t\n",
        "    \\left[\n",
        "      s_\\theta(x_t^i,\\bar\\sigma_t)_y - a \\log s_\\theta(x_t^i,\\bar\\sigma_t)_y + K(a)\n",
        "    \\right]\n",
        "}\\tag{7}\n",
        "$$\n",
        "\n",
        "where $K(a)=a(\\log a - 1)$ is the part that does *not* depend on the model. We also weight it with $\\sigma_t$ to emphasise harder/noisier examples. The $K(a) - a \\log s_\\theta$ term pulls $\\log s_\\theta$ toward $\\log a$ (i.e., toward the truth). The $K(a)$ term is constant w.r.t. the model parameters. It keeps the divergence non-negative and the algebra clean, but it can be optionally dropped during the training if we only care about the gradients.\n",
        "\n",
        "**Efficient implementation trick.**\n",
        "Eq. (7) sums over all $y \\neq x_t^i$. We can compute it efficiently by starting with a sum (or mean) over all vocabulary entries and subtracting the $y=x_t^i$ contribution. We'll also handle two special cases:\n",
        "\n",
        "* **No-move**: when $x_t=x_0$, i.e. the token survived the noise step.\n",
        "* **Move**: $x_t\\neq x_0$. We will build it from the two parts: with $y=x_0$ and $y\\notin \\left\\{ x_t, x_0 \\right\\}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iPjlV5LYmuXZ",
        "outputId": "753573fd-62a9-412c-85d9-589111b68495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-1651884094.py:15: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  sigma_bar:  (B, 1) tensor for \\bar\\sigma_t (integrated noise).\n"
          ]
        }
      ],
      "source": [
        "def score_entropy(\n",
        "    score_log: torch.Tensor,\n",
        "    sigma_bar: torch.Tensor,\n",
        "    x_t: torch.Tensor,\n",
        "    x0: torch.Tensor,\n",
        "    clamp_exp: float = 30.0,\n",
        "    eps: float = 1e-12,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute the Score Entropy Loss (Eq. 7) *without* the outer sigma_t multiplier.\n",
        "\n",
        "    Args:\n",
        "        score_log:  (B, L, V) tensor of model outputs = log s_theta(x_t, bar{sigma}_t)\n",
        "                    for each position and vocabulary element.\n",
        "        sigma_bar:  (B, 1) tensor for \\bar\\sigma_t (integrated noise).\n",
        "        x_t:        (B, L) int tensor with current noised tokens.\n",
        "        x0:         (B, L) int tensor with original clean tokens.\n",
        "        vocab_size: int, vocabulary size.\n",
        "        clamp_exp:  float, clamp for exponent to keep exp(score_log) stable.\n",
        "        eps:        float, small constant for numerical stability in logs/divides.\n",
        "\n",
        "    Returns:\n",
        "        loss:       (B, L) tensor containing Eq. (7) per token position (no sigma_t).\n",
        "        details:    dict with optional diagnostics for logging.\n",
        "    \"\"\"\n",
        "    B, L, vocab_size = score_log.shape\n",
        "    # 1) Precompute helpers\n",
        "    # stably compute exp(bar_sigma) - 1\n",
        "    esigm1 = torch.where(\n",
        "        sigma_bar < 0.5,\n",
        "        torch.expm1(sigma_bar),\n",
        "        torch.exp(sigma_bar) - 1\n",
        "    )\n",
        "\n",
        "    # ratio = non-diagonal terms (move) / diagonal terms (no-move) in Eq. (3)\n",
        "    ratio = esigm1 / (esigm1 + vocab_size)\n",
        "    # Clamp ratio away from 0 to avoid divide by zero and log(0)\n",
        "    ratio = torch.clamp(ratio, min=eps)\n",
        "\n",
        "    # We need both model predicted log s_theta and s = exp(log s_theta)\n",
        "    # Clamp the exponent to prevent overflow (safe since the loss uses first-order terms)\n",
        "    score_log = torch.clamp(score_log, max=clamp_exp)\n",
        "    s = torch.exp(score_log)\n",
        "    # We'll often need to take the values at a particular token indices\n",
        "    def take_at(logits: torch.Tensor, idx: torch.Tensor) -> torch.Tensor:\n",
        "        # logits: (B, L, V), idx: (B, L) -> (B, L)\n",
        "        return torch.gather(logits, dim=-1, index=idx[..., None]).squeeze(-1)\n",
        "\n",
        "    # 2) Build positive term in Eq. (7)\n",
        "    # Mean over all y, and then subtract out the y = x_t contribution\n",
        "    s_scaled   = s / (vocab_size - 1)  # scaled scores\n",
        "    s_mean_all = s_scaled.sum(dim=-1)    # (B, L)\n",
        "    s_at_xt    = take_at(s_scaled, x_t)  # (B, L)\n",
        "    pos_term   = s_mean_all - s_at_xt    # averages over y != x_t\n",
        "\n",
        "    # 3) Build negative term in Eq. (7)\n",
        "    # We need to consider a total of (V - 1) terms, split into two mutually exclusive cases:\n",
        "    # Case 1: x_t == x0 (no move); all y != x_t have the same a_y = ratio\n",
        "    #   there are a total of V - 1 such terms\n",
        "    # Case 2: x_t != x0 (move):\n",
        "    #   this can be split into two parts:\n",
        "    #   Part a: y == x0; with a_y = 1 / ratio\n",
        "    #     there is exactly 1 such term\n",
        "    #   Part b: y != x0 and y != x_t with a_y = 1\n",
        "    #     there are (V - 2) such terms\n",
        "    log_s_mean  = score_log.sum(dim=-1) / (vocab_size - 1)   # (B, L)\n",
        "    log_s_at_xt = take_at(score_log, x_t) / (vocab_size - 1) # (B, L)\n",
        "    base_neg    = log_s_mean - log_s_at_xt # averages over y != x_t\n",
        "\n",
        "    # Case split: no-move (x_t == x0) vs move (x_t != x0).\n",
        "    no_move = (x_t == x0)\n",
        "\n",
        "    # Case 1: no move (x_t == x0):\n",
        "    #   a_y = p(y|x0)/p(x_t|x0) = move / no-move = ratio\n",
        "    neg_term_no_move = ratio * base_neg\n",
        "\n",
        "    # Case 2: When x_t != x0:\n",
        "    # a_y = p(y|x0)/p(x_t|x0) = 1 / ratio when y = x0\n",
        "    # a_y = p(y|x0)/p(x_t|x0) = 1 otherwise\n",
        "    neg_term_move = take_at(score_log, x0) / (ratio * (vocab_size - 1)) + (vocab_size - 2) * base_neg / (vocab_size - 1)\n",
        "\n",
        "    neg_term = torch.where(no_move, neg_term_no_move, neg_term_move)\n",
        "\n",
        "    # 4) Build constant term K(a) summed over y != x_t.\n",
        "    # Again split into two mutually exclusive cases\n",
        "\n",
        "    # Case 1: no move (x_t == x0)\n",
        "    # y can be != x_t in V - 1 ways, each with a_y = ratio\n",
        "    const_no_move = ratio * (torch.log(ratio) - 1.0)\n",
        "\n",
        "    # Case 2: move (x_t != x0)\n",
        "    # a_y = p(y|x0)/p(x_t|x0) = 1 / ratio when y = x0\n",
        "    # a_y = p(y|x0)/p(x_t|x0) = 1 otherwise\n",
        "    const_move = ((-torch.log(ratio) - 1.0) / ratio - (vocab_size - 2)) / (vocab_size - 1)\n",
        "\n",
        "    const_term = torch.where(no_move, const_no_move, const_move)\n",
        "\n",
        "    # Final per-position loss (without the outer sigma_t multiplier):\n",
        "    loss = pos_term - neg_term + const_term  # (B, L)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6deBXeCH_FiE"
      },
      "source": [
        "### Loss function\n",
        "\n",
        "Let's define a `loss_function` that takes in the Diffusion model and a batch of data and does the following:\n",
        "  - randomly sample a time step for the noise for each sequence in the batch,\n",
        "  - generates the perturbed version of the batch using `perturb_batch()`,\n",
        "  - computes the score from our discrete diffusion model,\n",
        "  - generates and returns the loss using the `score_entropy()` defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6wmFnRxP_Hl9"
      },
      "outputs": [],
      "source": [
        "def loss_function(\n",
        "        model: GPT,\n",
        "        x0: torch.Tensor,\n",
        "        noise: GeometricNoise,\n",
        "        t: Optional[torch.Tensor]=None,\n",
        "        x_t: Optional[torch.Tensor]=None,\n",
        "        sampling_eps=1e-3\n",
        "    ) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the loss for a batch of data.\n",
        "    Args:\n",
        "        model:          discrete diffusion model\n",
        "        x0:             (B, L) Longtensor of original clean tokens.\n",
        "        noise:          a GeometricNoise instance\n",
        "        t:              (B,) float tensor with time steps in [0, 1]. If None, sampled uniformly.\n",
        "        x_t:            (B, L) int tensor with perturbed tokens. If None, generated on-the-fly.\n",
        "        sampling_eps:   float, small epsilon to avoid 0 or 1 time steps.\n",
        "    Returns:\n",
        "        loss:           scalar tensor with the loss.\n",
        "    \"\"\"\n",
        "\n",
        "    if t is None: # time step\n",
        "        t = (1 - sampling_eps) * torch.rand(x0.shape[0], device=x0.device) + sampling_eps\n",
        "\n",
        "    sigma_bar, sigma = noise(t)\n",
        "\n",
        "    if x_t is None:\n",
        "        x_t = perturb_batch(x0, sigma_bar[:, None])\n",
        "\n",
        "    log_score = model(x_t, sigma_bar)\n",
        "    loss = score_entropy(log_score, sigma_bar[:, None], x_t, x0)\n",
        "\n",
        "    loss = (sigma[:, None] * loss).mean(dim=-1).mean()\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffLVZTFy_1z-"
      },
      "source": [
        "### Optimiser\n",
        "\n",
        "We will use `AdamW` optimiser with a constant learning rate without any schedules to keep things simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kUTZefBe_zGg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxwQ7LVJmuXa"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "iJBuY4nx_qMB",
        "outputId": "2c54dbf5-4bd4-44e0-fe11-90c65f86a52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.1831793785095215\n",
            "5.5630693435668945\n",
            "5.414872646331787\n",
            "5.772920608520508\n",
            "5.401456832885742\n",
            "4.217007637023926\n",
            "5.551151275634766\n",
            "4.036837577819824\n",
            "6.236654281616211\n",
            "5.593850135803223\n",
            "6.462361812591553\n",
            "5.069202423095703\n",
            "4.514479160308838\n",
            "5.0613112449646\n",
            "3.2677175998687744\n",
            "4.087515830993652\n",
            "5.8715739250183105\n",
            "5.000021457672119\n",
            "4.3644328117370605\n",
            "5.402681350708008\n",
            "4.398952960968018\n",
            "5.328688621520996\n",
            "4.425197601318359\n",
            "4.624154567718506\n",
            "4.374664306640625\n",
            "3.980660915374756\n",
            "4.627373695373535\n",
            "4.546439170837402\n",
            "3.570584535598755\n",
            "4.5562238693237305\n",
            "4.874554634094238\n",
            "4.125526428222656\n",
            "4.19124698638916\n",
            "4.313258647918701\n",
            "2.635503053665161\n",
            "3.549751043319702\n",
            "4.067028999328613\n",
            "4.750113487243652\n",
            "4.118993759155273\n",
            "3.9710073471069336\n",
            "4.918059825897217\n",
            "5.19891357421875\n",
            "4.170533657073975\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-310535167.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_eps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        batch = batch.to(device)\n",
        "        loss = loss_function(model, batch, noise, sampling_eps=sigma_min)\n",
        "        print(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch} loss: {loss.item()}\")\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjtukNc2muXa"
      },
      "source": [
        "## Inference (Sampling)\n",
        "\n",
        "Once our score model $s_\\theta$ is trained, we can use it to generate new sequences by running the diffusion process *backwards in time*.\n",
        "This corresponds to constructing the **reverse diffusion matrix** $\\bar Q_t$ from Eq. (5), which governs how we move from noisy tokens back toward clean data.\n",
        "\n",
        "### 1. Reverse-time simulation\n",
        "\n",
        "In principle, we can approximate the reverse process in Eq. (4) with a small **Euler step**:\n",
        "$$\n",
        "p(x_{t+\\Delta t} = y \\mid x_t = x) = \\delta_{xy} + \\bar Q_t(y, x) \\Delta t + O(\\Delta t^2).\n",
        "$$\n",
        "Here, $\\bar Q_t(y, x)$ gives the instantaneous probability flow from token $x$ to token $y$. But this process is extremely slow as the way we defined $Q_t$, we are only allowed to update one token at a time (1-Hamming distance) in the text. It takes many steps to completely denoise to the text.\n",
        "\n",
        "### 2. $\\tau$-leaping: parallel updates\n",
        "\n",
        "To speed things up, we could use $\\tau$-leaping (Gillespie, 2001). Instead of advancing one token at a time, $\\tau$-leaping updates *all* positions simultaneously over a small time step $\\Delta t$. For each token $x_t^i$ in the sequence $x_t$, we sample its next state independently:\n",
        "$$\n",
        "\\Pr(x_{t-\\Delta t}^i = y) = \\delta_{x_t^i}(y) + \\Delta t Q_t(x_t^i, y) s_\\theta(\\mathbf{x}_t, t)_{i, y}$$\n",
        "\n",
        "Intuitively, under $\\tau$-leaping each token \"jumps\" to a new symbol with a rate determined by both:\n",
        "\n",
        "  - the **forward rate matrix** $Q_t$, and\n",
        "  - our **score model** $s_\\theta$, which encodes ratios between symbol probabilities.\n",
        "\n",
        "While $\\tau$-leaping is much faster than single-event simulation, it still uses $s_\\theta$ in a fairly crude way, it just modulates the rate of a random walk. Also, the time step $\\Delta t$ needs to be kept small to keep the error small. We can do better.\n",
        "\n",
        "### 3. Tweedie denoiser: optimal reverse step\n",
        "\n",
        "In the continuous world (e.g., image diffusion), a celebrated result called **Tweedie’s formula** tells us how to get the *optimal* denoised estimate from noisy data, given the score function. It gives you a direct formula to get a good estimate of the original clean image $x_0$ from the noisy image $x_t$, not just $x_{t-\\Delta t}$ over a small time-step $\\Delta t$. *Lou et al.* discretise it and build a Tweedie denoiser analogue for our token diffusion:\n",
        "\n",
        "$$p^{\\text {tweedie}} (x^i_{t-\\Delta t} \\mid x^i_t) \\approx(\\exp (-\\sigma_t^{\\Delta t} Q^{\\text {tok}}) s_{\\theta} (x_t, t)_i)_{x^i_{t− \\Delta t}} \\cdot \\exp (\\sigma_t^{\\Delta t} Q^{\\text {tok}}) (x_t^i,x_{t− \\Delta t}^i)\\tag{8}$$\n",
        "\n",
        "where $\\sigma_t^{\\Delta t} = (\\bar \\sigma(t) - \\bar \\sigma(t-\\Delta t))$. The matrix exponential $\\exp(\\bar \\sigma_t Q^{\\text {tok}})$ is essentially an *finite-time evolution operator\"; it tells you how the whole system changes after a finite amount of time $t$.\n",
        "\n",
        "Think of the Equation (8) like **Bayes' Rule**\n",
        "$$P(A \\mid B) = \\frac {P(B \\mid A) P(A)} {P(B)}$$\n",
        "\n",
        "with $A = x^i_{t-\\Delta t}$ and $B=x^i_t$, where:\n",
        "\n",
        "  - The reverse process: $P(A \\mid B) = p (x^i_{t-\\Delta t} \\mid x^i_t)$ ,\n",
        "  - The forward process: $P(B \\mid A) = \\exp (\\sigma_t^{\\Delta t} Q^{\\text {tok}}) (x_t^i,x_{t − \\Delta t}^i)$\n",
        "  - The prior $P(A)$ and evidence $P(B)$ : $\\frac {P(A)} {P(B)}  = (\\exp (-\\sigma_t^{\\Delta t} Q^{\\text {tok}}) s_{\\theta} (x_t, t)_i)_{x^i_{t− \\Delta t}}$\n",
        "\n",
        "Thus, the model reuses forward dynamics **and** its learned score ratios to create sharper, more accurate denoising transitions.\n",
        "\n",
        "### 4. Implementation detail\n",
        "\n",
        "Let's code up Eq. 8 now. We'll implement two helper functions:\n",
        "\n",
        "  1. `transition()`: computes the forward diffusion kernel\n",
        "   (\\exp(\\sigma_t^{\\Delta t} Q^{\\text{tok}})).\n",
        "  2. `staggered_score()`: applies the inverse operator $\\exp(-\\sigma_t^{\\Delta t} Q^{\\text{tok}})$ to the model's score output. We'll define a `sample_categorical()` helper to draw discrete samples from these probabilities using a numerically stable Gumbel-based method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "a1Q3Www1UjEq"
      },
      "outputs": [],
      "source": [
        "def transition(x_t: torch.Tensor, delta_sigma: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Forward transition kernel:\n",
        "        exp(σ_t^Δt Q^{tok})(x_t, y)\n",
        "\n",
        "    Approximates the finite-time forward diffusion probability of moving from token x_t to y\n",
        "    after a noise increment of Δσ = σ_t^{Δt}.\n",
        "\n",
        "    Args:\n",
        "        x_t:          (B, L) integer tensor of current tokens.\n",
        "        delta_sigma:  scalar tensor representing σ_t^{Δt}.\n",
        "\n",
        "    Returns:\n",
        "        trans_probs:  (B, L, V) tensor of categorical probabilities over next tokens.\n",
        "    \"\"\"\n",
        "    # Uniform mixing term from exp(delta_sigma * Q^{tok})\n",
        "    # with the help of Eq. (3), this translates to:\n",
        "    base_prob = (1 - torch.exp(-delta_sigma[..., None])) / vocab_size\n",
        "    trans = torch.ones(*x_t.shape, vocab_size, device=x_t.device) * base_prob\n",
        "\n",
        "    # Remove the uniform contribution for the current token\n",
        "    trans = trans.scatter(-1, x_t[..., None], torch.zeros_like(trans))\n",
        "\n",
        "    # Ensure that probabilities across the vocabulary sum to 1\n",
        "    diag_fill = 1 - trans.sum(dim=-1, keepdim=True)\n",
        "    trans = trans.scatter(-1, x_t[..., None], diag_fill)\n",
        "    return trans\n",
        "\n",
        "\n",
        "def staggered_score(score, delta_sigma):\n",
        "    \"\"\"\n",
        "    Applies the inverse exponential operator:\n",
        "        exp(-σ_t^Δt Q^{tok}) s_θ(x_t, t)\n",
        "\n",
        "    This \"staggered\" score correction accounts for the finite time-step Δt.\n",
        "\n",
        "    Args:\n",
        "        score:        (B, L, V) tensor, model output s_θ(x_t, t)\n",
        "        delta_sigma:  scalar tensor representing σ_t^{Δt}\n",
        "\n",
        "    Returns:\n",
        "        adjusted_score: (B, L, V) tensor, transformed score\n",
        "    \"\"\"\n",
        "    vocab_size = score.shape[-1]\n",
        "    exp_factor = torch.exp(-delta_sigma)[..., None]  # (B, L, 1)\n",
        "    correction = ((exp_factor - 1) / (vocab_size * exp_factor)) * score.sum(dim=-1, keepdim=True)\n",
        "    return correction + score / exp_factor\n",
        "\n",
        "\n",
        "def sample_categorical(probs: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Sample from a batch of categorical distributions using the Gumbel-max trick.\n",
        "\n",
        "    Args:\n",
        "        probs: (B, L, V) tensor of probabilities that sum to 1 along dim=-1.\n",
        "\n",
        "    Returns:\n",
        "        samples: (B, L) tensor of sampled token indices.\n",
        "    \"\"\"\n",
        "    # Add a small epsilon for numerical stability\n",
        "    eps = 1e-10\n",
        "    gumbel_noise = -torch.log(-torch.log(torch.rand_like(probs) + eps) + eps)\n",
        "    return torch.argmax(torch.log(probs + eps) + gumbel_noise, dim=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMFqYeBCMwS-"
      },
      "source": [
        "### Load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ln9K21FDM29c",
        "outputId": "f8d3a737-b1a1-4842-f6d0-5bc36ae182ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://raw.githubusercontent.com/ash80/diffusion-gpt/master/pretrained_model/model_epoch_25.pth\" to /root/.cache/torch/hub/checkpoints/model_epoch_25.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.8M/44.8M [00:00<00:00, 416MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (sigma_map): TimestepEmbedder(\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
              "      (1): SiLU()\n",
              "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (transformer): ModuleDict(\n",
              "    (wte): Embedding(65, 384)\n",
              "    (wpe): Embedding(256, 384)\n",
              "    (drop): Dropout(p=0.2, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-5): 6 x DDiTBlock(\n",
              "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): SelfAttention(\n",
              "          (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
              "          (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
              "          (gelu): GELU(approximate='none')\n",
              "          (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (adaLN_modulation): Linear(in_features=64, out_features=2304, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): DDitFinalLayer(\n",
              "    (norm_final): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    (linear): Linear(in_features=384, out_features=65, bias=True)\n",
              "    (adaLN_modulation): Linear(in_features=64, out_features=768, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.load_state_dict(\n",
        "    torch.hub.load_state_dict_from_url(\n",
        "        'https://raw.githubusercontent.com/ash80/diffusion-gpt/master/pretrained_model/model_epoch_25.pth',\n",
        "        map_location=device\n",
        "    )\n",
        ")\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfUJm8rXXMGZ"
      },
      "source": [
        "### Generate random samples\n",
        "\n",
        "Now let's test our sampling components. We'll start with a random sequence of tokens $x_t$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_os__y9McNdT",
        "outputId": "eaf2ae44-9c24-43d3-fec4-6f6399027e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3CWNjze:auwNdMsIMHsneyXWBhII$!sMLzGzQudUMdPxvRz:rWpViddro-..vJAcAtA'zOXkwH\n",
            "FTmInUbTnGv-;pDGT!xz,;upAVKOUA'&VIv\n",
            "Ym&RqlOUUGtanMLjbjqprHN3VEB.ZilAwwG$Q!pbWNmhsiBaiZBkXXUwFX& oR:yr'Hl&Mz$\n",
            "O'GGPrpDRtKMMNQjq;ACKNPq!E-wic.j$UX o\n",
            "hZOZhsMRrf UEPSpCm&t:tnq\n",
            "aOB$fs!I?\n"
          ]
        }
      ],
      "source": [
        "x = torch.randint(0, vocab_size, (1, context_length)).to(device)\n",
        "print_wrapped(decode(x[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DDQOea9cMRw"
      },
      "source": [
        "### Sampling config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7JCL4EGtXYA-"
      },
      "outputs": [],
      "source": [
        "steps = 128\n",
        "eps = 1e-5\n",
        "timesteps = torch.linspace(1, eps, steps + 1, device=device)\n",
        "step_size = (1 - eps) / steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEUwE59-muXb"
      },
      "source": [
        "### Denoising"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI-DhHy0Mr2Q",
        "outputId": "ea7352fe-adf9-429a-b3cd-9c88a57be954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded Text at step 128:\n",
            "\n",
            "trous man's comply war than so from.\n",
            "\n",
            "DUREEN:\n",
            "The unsistors tragles, were you a father?\n",
            "Shall we broke alone.\n",
            "\n",
            "HENRY OF YORK:\n",
            "Right with lead, I'll have add it but, more need.\n",
            "We that any answer'd your table?\n",
            "\n",
            "HENRY BOLINGBBROKE:\n",
            "Nay, presenance it do we f\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Start with a fresh random sample\n",
        "x = torch.randint(0, vocab_size, (1, context_length), device=device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(steps + 1):\n",
        "        t = timesteps[i] * torch.ones(x.shape[0], 1, device=device)\n",
        "        curr_sigma_bar = noise(t)[0]\n",
        "        if i < steps:\n",
        "            next_sigma_bar = noise(t - step_size)[0]\n",
        "            delta_sigma = curr_sigma_bar - next_sigma_bar\n",
        "\n",
        "            log_score = model(x, curr_sigma_bar)\n",
        "            score = torch.exp(log_score)\n",
        "\n",
        "            stag_score = staggered_score(score, delta_sigma)\n",
        "            probs = stag_score * transition(x, delta_sigma)\n",
        "            x = sample_categorical(probs)\n",
        "\n",
        "        else:\n",
        "            # last denoising step\n",
        "            # delta_sigma = curr_noise_bar - 0\n",
        "            delta_sigma = curr_sigma_bar\n",
        "\n",
        "            log_score = model(x, curr_sigma_bar)\n",
        "            score = torch.exp(log_score)\n",
        "\n",
        "            stag_score = staggered_score(score, delta_sigma)\n",
        "            probs = stag_score * transition(x, delta_sigma)\n",
        "\n",
        "            x = sample_categorical(probs)\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        print(f'Decoded Text at step {i}:', flush=True, end='\\n\\n')\n",
        "        print_wrapped(decode(x[0]), end='\\n\\n', flush=True)\n",
        "        # time.sleep(0.02)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqv8TpDJhEvT"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, we built a discrete diffusion GPT model for character-level text generation, illustrating how discrete diffusion can serve as a powerful alternative to autoregressive language modeling. We introduced the mathematical framework of discrete diffusion, using a continuous-time Markov chain to define how noise is added and removed from discrete tokens.\n",
        "\n",
        "Unlike autoregressive models, our diffusion model can denoise all tokens in parallel, offering potential speed advantages during inference. However, it also limits optimizations such as KV caching, since the entire sequence evolves simultaneously.\n",
        "\n",
        "We used a uniform rate matrix for diffusing tokens, though we could also explore diffusion with other rate matrices. Lou et al also used absorb rate matrices, where tokens transition from masked to correct states during denoising. Overall, discrete diffusion models offer a compelling new direction for text generation, nicely blending mathematical elegance with practical promise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8l7RM_AmuXb"
      },
      "source": [
        "## Acknowledgement\n",
        "\n",
        "This notebook builds on top of Andrej Karpathy's [nanoGPT](https://github.com/karpathy/nanoGPT) and A. Lou's [Score-Entropy-Discrete-Diffusion](https://github.com/louaaron/Score-Entropy-Discrete-Diffusion) repositories and relies upon the mathematical framework presented in the paper A. Lou et al., \"Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution\", [arXiv:2310.16834](https://arxiv.org/abs/2310.16834) (2024).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}